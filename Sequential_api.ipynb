{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train =scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7842 - val_loss: 0.7693\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 911us/step - loss: 3.6416 - val_loss: 0.5264\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 875us/step - loss: 0.5312 - val_loss: 0.4046\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 853us/step - loss: 0.4051 - val_loss: 0.3923\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 877us/step - loss: 0.4033 - val_loss: 0.6584\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3857 - val_loss: 0.5624\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3727 - val_loss: 0.3429\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 902us/step - loss: 0.3601 - val_loss: 0.3398\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3542 - val_loss: 0.3480\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 939us/step - loss: 0.3473 - val_loss: 0.4082\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.3282\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 973us/step - loss: 0.3441 - val_loss: 0.3322\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.3367\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 0.3319\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.3222\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3296\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 910us/step - loss: 0.3356 - val_loss: 0.3175\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 880us/step - loss: 0.3340 - val_loss: 0.3247\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.3323 - val_loss: 0.3274\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 846us/step - loss: 0.3310 - val_loss: 0.3140\n",
      "162/162 [==============================] - 0s 562us/step - loss: 0.3194\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5  , 1.024, 3.413])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.621834 ],\n",
       "       [2.0484762],\n",
       "       [2.8577476]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수형 API 복잡한 모델 만들기\n",
    "   - Wide & Deep 신경망 만들기\n",
    "   - 입력의 일부 또는 전체가 출력층에 바로연결\n",
    "   - 신경망을 복잡한 패턴과 간단한 규칙을 모두 학습가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력이 여러개 인경우\n",
    " - 입력을 다중으로 입력하고 싶은경우가 있음. \n",
    " - ex) 상품정보를 predict하는 모델을 만들경우 흔히 상품페이지에는 상품명과 하위클래스로 옵션명이 있다 \n",
    " -     이러한 경우 상품명과 옵션명을 동시에 입력으로 넣어 predict 하도록 설계하였다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs= [input_A, input_B], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.1226 - val_loss: 0.9642\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8555 - val_loss: 0.7331\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7158 - val_loss: 0.6659\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6673 - val_loss: 0.6322\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6388 - val_loss: 0.6072\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6151 - val_loss: 0.5880\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5962 - val_loss: 0.5683\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5796 - val_loss: 0.5548\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5651 - val_loss: 0.5396\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5526 - val_loss: 0.5286\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5425 - val_loss: 0.5188\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5335 - val_loss: 0.5112\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5259 - val_loss: 0.5041\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5179 - val_loss: 0.4986\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5118 - val_loss: 0.4964\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5097 - val_loss: 0.4907\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5044 - val_loss: 0.4867\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4989 - val_loss: 0.4869\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4968 - val_loss: 0.4815\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4924 - val_loss: 0.4777\n",
      "162/162 [==============================] - 0s 865us/step - loss: 0.4770\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                   validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여러 출력이 필요한 경우\n",
    "- 여러 출력이 필요한 작업일 경우 \n",
    "- ex) 그림에있는 주요 물체를 분류하고 위치를 알아야 할 수 있습니다. 이때, 회귀 작업 과 분류 작업을 함께 하는 경우 입니다(Google Vision Api 가 제공하는 작업)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='main_output')(concat)\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 출력층은 각각의 loss fuction이 필요하기 때문에 리스트로 전달\n",
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer='sgd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9922 - main_output_loss: 0.8820 - aux_output_loss: 1.9837 - val_loss: 0.6449 - val_main_output_loss: 0.5744 - val_aux_output_loss: 1.2797\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7380 - main_output_loss: 0.6849 - aux_output_loss: 1.2158 - val_loss: 0.5860 - val_main_output_loss: 0.5277 - val_aux_output_loss: 1.1108\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5803 - main_output_loss: 0.5302 - aux_output_loss: 1.0311 - val_loss: 0.5273 - val_main_output_loss: 0.4813 - val_aux_output_loss: 0.9415\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5299 - main_output_loss: 0.4892 - aux_output_loss: 0.8958 - val_loss: 0.5066 - val_main_output_loss: 0.4682 - val_aux_output_loss: 0.8530\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5130 - main_output_loss: 0.4778 - aux_output_loss: 0.8299 - val_loss: 0.4922 - val_main_output_loss: 0.4591 - val_aux_output_loss: 0.7908\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4921 - main_output_loss: 0.4613 - aux_output_loss: 0.7690 - val_loss: 0.4786 - val_main_output_loss: 0.4492 - val_aux_output_loss: 0.7434\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4893 - main_output_loss: 0.4623 - aux_output_loss: 0.7323 - val_loss: 0.4801 - val_main_output_loss: 0.4543 - val_aux_output_loss: 0.7120\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4716 - main_output_loss: 0.4464 - aux_output_loss: 0.6990 - val_loss: 0.4574 - val_main_output_loss: 0.4323 - val_aux_output_loss: 0.6833\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4586 - main_output_loss: 0.4352 - aux_output_loss: 0.6691 - val_loss: 0.4575 - val_main_output_loss: 0.4346 - val_aux_output_loss: 0.6639\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4492 - main_output_loss: 0.4261 - aux_output_loss: 0.6571 - val_loss: 0.4341 - val_main_output_loss: 0.4122 - val_aux_output_loss: 0.6315\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4392 - main_output_loss: 0.4179 - aux_output_loss: 0.6309 - val_loss: 0.4253 - val_main_output_loss: 0.4037 - val_aux_output_loss: 0.6196\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4384 - main_output_loss: 0.4189 - aux_output_loss: 0.6131 - val_loss: 0.4223 - val_main_output_loss: 0.4020 - val_aux_output_loss: 0.6051\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4268 - main_output_loss: 0.4079 - aux_output_loss: 0.5973 - val_loss: 0.4184 - val_main_output_loss: 0.4000 - val_aux_output_loss: 0.5846\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4226 - main_output_loss: 0.4040 - aux_output_loss: 0.5903 - val_loss: 0.4172 - val_main_output_loss: 0.3982 - val_aux_output_loss: 0.5884\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4107 - main_output_loss: 0.3924 - aux_output_loss: 0.5754 - val_loss: 0.4105 - val_main_output_loss: 0.3924 - val_aux_output_loss: 0.5730\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4207 - main_output_loss: 0.4028 - aux_output_loss: 0.5818 - val_loss: 0.4088 - val_main_output_loss: 0.3899 - val_aux_output_loss: 0.5797\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4116 - main_output_loss: 0.3953 - aux_output_loss: 0.5579 - val_loss: 0.3934 - val_main_output_loss: 0.3767 - val_aux_output_loss: 0.5440\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4096 - main_output_loss: 0.3953 - aux_output_loss: 0.5382 - val_loss: 0.3893 - val_main_output_loss: 0.3733 - val_aux_output_loss: 0.5331\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3904 - main_output_loss: 0.3753 - aux_output_loss: 0.5258 - val_loss: 0.3877 - val_main_output_loss: 0.3719 - val_aux_output_loss: 0.5298\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3882 - main_output_loss: 0.3739 - aux_output_loss: 0.5177 - val_loss: 0.3867 - val_main_output_loss: 0.3717 - val_aux_output_loss: 0.5220\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3718 - main_output_loss: 0.3576 - aux_output_loss: 0.4999\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6289976],\n",
       "       [2.1785896],\n",
       "       [2.965984 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.380136 ],\n",
       "       [2.2462208],\n",
       "       [3.3289845]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 서브클래싱 API로 동적 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):# keras의 Model 클래스를 상속한 다음 생성자 안에 필요한 층 생성\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "    \n",
    "model = WideAndDeepModel()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스의 HDF5 포맷을 사용하여 모델 구조와 층의 모든 모델 파라미터를 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([...])\n",
    "model.complie([...])\n",
    "model.fit([...])\n",
    "model.save(';;;.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(';;;.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 콜백 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 741us/step - loss: 0.3291\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 697us/step - loss: 0.3399\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 761us/step - loss: 0.3332\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.3273\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 769us/step - loss: 0.3249\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.3242\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 745us/step - loss: 0.3239\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 744us/step - loss: 0.3248\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 675us/step - loss: 0.3220\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 736us/step - loss: 0.3215\n"
     ]
    }
   ],
   "source": [
    "checkpoint_db = keras.callbacks.ModelCheckpoint('my_keras_model.h5')\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_db])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3215 - val_loss: 0.3179\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.3220 - val_loss: 0.3138\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 944us/step - loss: 0.3205 - val_loss: 0.3146\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 888us/step - loss: 0.3194 - val_loss: 0.3199\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.3113\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3176 - val_loss: 0.3025\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3181 - val_loss: 0.3143\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 930us/step - loss: 0.3163 - val_loss: 0.3137\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 949us/step - loss: 0.3173 - val_loss: 0.3087\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.3150 - val_loss: 0.3028\n"
     ]
    }
   ],
   "source": [
    "### 최상의 모델로 복원\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3170 - val_loss: 0.3287\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 941us/step - loss: 0.3160 - val_loss: 0.3085\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.3160 - val_loss: 0.3117\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.3194 - val_loss: 0.3196\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3163 - val_loss: 0.3073\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.3148 - val_loss: 0.3051\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 968us/step - loss: 0.3158 - val_loss: 0.3123\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3142 - val_loss: 0.3006\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 941us/step - loss: 0.3131 - val_loss: 0.3076\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 980us/step - loss: 0.3130 - val_loss: 0.3139\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.3208 - val_loss: 0.3184\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.3161 - val_loss: 0.3075\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.3127 - val_loss: 0.3034\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.3121 - val_loss: 0.3164\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3133 - val_loss: 0.3036\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3117 - val_loss: 0.3215\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 958us/step - loss: 0.3099 - val_loss: 0.2983\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.3118\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3106\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.2980\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3006\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3089 - val_loss: 0.3014\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.3010\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.3076\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3081 - val_loss: 0.3104\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 953us/step - loss: 0.3104 - val_loss: 0.3191\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 943us/step - loss: 0.3096 - val_loss: 0.3042\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.3091 - val_loss: 0.2977\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 892us/step - loss: 0.3082 - val_loss: 0.3027\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.3089 - val_loss: 0.2991\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3088 - val_loss: 0.2997\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 906us/step - loss: 0.3078 - val_loss: 0.3226\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3073 - val_loss: 0.2976\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3067 - val_loss: 0.2980\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.3019\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.3077 - val_loss: 0.3289\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 958us/step - loss: 0.3065 - val_loss: 0.3085\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 953us/step - loss: 0.3064 - val_loss: 0.3068\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.3056 - val_loss: 0.3239\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 930us/step - loss: 0.3068 - val_loss: 0.3120\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.3059 - val_loss: 0.2977\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.3240\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.3064 - val_loss: 0.3006\n"
     ]
    }
   ],
   "source": [
    "# early_stopping 사용하기\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "histroy = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 역전파란 무엇이고 어떻게 작동하나요? 역전파와 후진 모드 자동 미분의 차이점은 무엇인가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 먼저 모델의 모든 파리미터(가중치와 편향)대한 비용 함수의 그래디언트를 계산하고, 이 그래디언트를 사용해 경사 하강법 스텝을 수행합니다. 역전파 단계는 모델 파라미터가 비용함수를 최소화하는 값으로 수렴할 때까지 훈련 배치에서 일반적으로 수천 혹은 수백만 번 수행됩니다.\n",
    "그래디언트를 계산하기 위해 연전파는 후진 모드 자동 미분을 사용합니다. 후진 모드 자동 미분은 계산 그래프의 정방향 계산에서 현재 훈련 배치에 대한 모든 노드의 값을 구합니다. 그 다음에 역방향 계산에서 한번에 모든 그래디어트를 구합니다. 역전파는 그래디언트 계산과 경사 하강법 스텝을 여러 번 수행하여 인공 신경망을 훈련시키는 전체 프로세스를 의미합니다. 이와 다르게 후진 모드 자동 미분은 그래디언트를 효과적으로 계산하는 하나의 기법으로 역전파에서 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
